<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>CNW Wildlife Identification</title>

    <!-- Bootstrap Core CSS -->
    <link href="/static/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="/static/vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">

    <!-- Theme CSS -->
    <link href="/static/css/grayscale.min.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">

    <!-- Navigation -->
    <nav class="navbar navbar-custom navbar-fixed-top" role="navigation">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-main-collapse">
                    Menu <i class="fa fa-bars"></i>
                </button>
                <a class="navbar-brand page-scroll" href="#page-top">
                    <i class="fa fa-play-circle"></i> <span class="light">Wildlife</span> Identification
                </a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse navbar-right navbar-main-collapse">
                <ul class="nav navbar-nav">
                    <!-- Hidden li included to remove active class from about link when scrolled up past about section -->
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#about">About</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#download">Web App</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#contact">Contact</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Intro Header -->
    <header class="intro">
        <div class="intro-body">
            <div class="container">
                <div class="row">
                    <div class="col-md-8 col-md-offset-2">
                        <h1 class="brand-heading">wildlife<br>id</h1>
                        <p class="intro-text">neural network classification of wildlife
                            <br>in remote camera images</p>
                        <a href="#about" class="btn btn-circle page-scroll">
                            <i class="fa fa-angle-double-down animated"></i>
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- About Section -->
    <section id="about" class="container content-section text-center">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h1>About this project</h1>

                <h1 id="speciesidentificationimageclassificationinwildliferemotecamerastudies">Species Identification: Image Classification in Wildlife Remote Camera Studies</h1>

                    <p>This project aims to classify wildlife in images from the Conservation Northwest Wildlife Monitoring Project. The classification model will generate a vector of image features through a pre-trained convolutional neural network and then classify these vectors with a support vector machine.</p>

                    <h2 id="__businessunderstanding__"><strong>Business Understanding:</strong></h2>

                    <p>Conservation Northwest (CNW) is a non-profit land conservation organization dedicated to protecting and conserving wild lands from the Washington Coast to the BC Rockies. One of CNW's ongoing efforts is the Citizen Wildlife Monitoring Project (CWMP), organizing citizen-scientist volunteers to monitor and document wildlife using remote cameras where state and federal agencies do not have the resources to go.
                    The CWMP is now in its tenth year. The project depends largely on volunteers, not only to maintain and monitor the cameras, but also to manually sort and categorize hundreds of thousands of resulting photos - many of which do not contain any animal and must be removed from the database.
                    Image recognition, and machine learning technologies provide a significant opportunity for streamlining volunteer efforts and improving the consistency of the resultant data. Images from 2015 and 2014 have already been categorized by hand, and are available for use in model training. Images from seven previous years (2007 - 2013) and from the current field season (2016) have yet to be analyzed, so an automated system would be of immediate benefit to the organization.
                    The ideal system would automate three tasks</p>

                    <ul>
                    <li>Remove of 'False Triggers' - images with no animal.</li>

                    <li>Group photos into ‘Events' - multiple images of the same animal around the same time</li>

                    <li>Identify which species are present in each photo.</li>
                    </ul>

                    <p>This project starts with the identification of species because false triggers have already been removed from the initial dataset manually, and event classification data is not included in the initial dataset.</p>

                    <p><br></p>

                    <h2 id="__thedata__"><strong>The Data</strong></h2>

                    <p>An extensive set of photographs is available for analysis: ~120000 images from 2015 alone. Verified species information is included in the metadata associated with each image, making Species Identification a convenient starting point for this project.
                    The primary information used for prediction is the photographs themselves. The cameras used in the wildlife monitoring project take three photos consecutively each time they are triggered. Therefore timestamps and adjacent photos (or their predicted classifications) may also provide useful information to a machine learning model.
                    False triggers have already been removed from the data set, and retrieving event classification information has proven technically challenging. These directions are better suited to a longer project and may require minor changes to the CWMP protocol in order to make modeling more feasible.
                    Data preparation required some effort. Directory naming across the 2015 image set is somewhat inconsistent and there are occasional duplicate photos either in differently named directories, or in the same directory with different names (e.g. 'img401' and 'img401 (2)'). Metadata also needed to be separated from the images and formatted into an appropriate data structure.</p>

                    <p><br></p>

                    <h2 id="__modeling__"><strong>Modeling</strong></h2>

                    <p>In the current phase of modeling, a Support Vector Machine (SVM) is applied to features extracted from TensorFlow's pre-trained convolutional neural network, Inception-v3. For the first phase, animal species have been grouped into five categories:</p>

                    <ul>
                    <li>Canine (coyote, wolf, and domestic dog)</li>

                    <li>Feline (bobcat, lynx, cougar)</li>

                    <li>Ungulate (deer, elk, moose)</li>

                    <li>Small (squirrels, birds, mice, weasels)</li>

                    <li>Other (humans, bear, skunk, wolverine, marmot).</li>
                    </ul>

                    <p>Snow-shoe Hares were a very unbalanced group, and posed a particular challenge to the model (being a small white animal on a snowy background) and so were removed from the training set.</p>

                    <p>In upcoming stages I plan to use motion detection (OpenCV or similar) across consecutive images to help identify critical areas of the photographs and help account for new backgrounds. This will hopefully allow the model to correctly predict species even for camera locations not seen during training.</p>

                    <p>An alternate strategy under consideration would be to experiment with Facebook's SharpMask module, and attempt to identify where in the photos the animals are located. This information could then be used for further classification.</p>

                    <p>In addition to TensorFlow and scikit-learn, my project uses Tamás Gulácsi's IPTCInfo python module for metadata extraction.</p>

                    <p><br></p>

                    <h2 id="__resultsandevaluation__"><strong>Results and Evaluation</strong></h2>

                    <p>The current model was trained on a subset of the data - approximately 4000 photos. To evaluate this model I split the data subset randomly into test and training groups. It is important to note that these photos where all from one of three training locations. As a result animals are often seen in similar locations and at similar times of day.</p>

                    <p>The model achieved 85-98% in-class accuracy for each of the five categories on the test portion of the subset. Only the 'small' category fell below 94% and this lower rating may be at least partially explained by class imbalance. The 'Small' category was roughly one fourth the size of the other groups.</p>

                    <p>Results on images from other locations were generally weak. However, on a small sample (~150 photos) of very clear photos found online, the model had accuracy of 55-75% per category.</p>

                    <p>I expect that taking backgrounds into account through motion capture will help significantly. I also plan to test the model on test and training groups at the same location separated solely by time.</p>

                    <p><br></p>

                    <h2 id="__deployment__"><strong>Deployment</strong></h2>

                    <p>Checkout the Web App below! This app allows the user to upload a photo and receive a prediction from the model. Because your photos are likely not from the same location, the results are often entertaining!</p>

                    <p>The eventual plan is to build this system into an app that will allow volunteers with CWMP to upload and entire directory and receive predictions. Predictions could then be used to flag false triggers, and suggest event grouping. </p>
                    
                    <p>Special thanks to everyone who made this project possible including: <a href="http://www.conservationnw.org/">Conservation Northwest</a> for the images used in model training; <a href="http://davidmoskowitz.net/">David Moskowitz</a> for guidance and support in creating the project and providing the initial inspiration; and to the instructional staff at the <a href="http://www.galvanize.com/campuses/seattle-pioneer-square/">Galvanize Seattle, Data Science Immersive Program</a> for sharing their incredible knowledge and expertise.</p>
            </div>
        </div>
    </section>

    <!-- Download Section -->
    <section id="download" class="content-section text-center">
        <div class="download-section">
            <div class="container">
                <div class="col-lg-8 col-lg-offset-2">
                    <h2>Identification Web app</h2>
                    <br>
                    <p>This web app takes an image and calculates a prediction based on other images the model has seen. The web app is intended primarily for proof of concept and entertainment. Because the initial model was trained on a very small set of backgrounds, it is rather imprecise on general photos. You have been warned!</p>
                    <p>Still, so long as the animal is unobscured, decent predictions can still be obtained.</p>
                    <p>The identification web app is very much a work in progress. It currently accepts only images with a .jpg or .JPG extension. Feel free to give it a try</p>
                    <br>
                    <a href="/upload" class="btn btn-default btn-lg">Classify an Image!</a>
                </div>
            </div>
        </div>
    </section>

    <!-- Contact Section -->
    <section id="contact" class="container content-section text-center">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h2>Contact</h2>
                <p>Feel free get in touch, ask questions, or even just say hello!</p>
                <p><a href="mailto:evan.wildlife.id@gmail.com">evan.wildlife.id@gmail.com</a>
                </p>
                <ul class="list-inline banner-social-buttons">
                  <!-- add link to linkedin? anything else?-->
                    <li>
                        <a href="https://github.com/coradek/CNW_Wildlife_Identification" class="btn btn-default btn-lg"><i class="fa fa-github fa-fw"></i> <span class="network-name">See This Project on Github</span></a>
                    </li>
                    <li>
                        <a href="https://www.linkedin.com/in/evan-adkins42" class="btn btn-default btn-lg"><i class="fa fa-linkedin fa-fw"></i> <span class="network-name">Connect on LinkedIn</span></a>
                    </li>
                </ul>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer>
        <div class="container text-center">
            <p>Copyright &copy; Evan Adkins 2016</p>
            <p>Photos Copyright &copy; Conservation Northwest 2016</p>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="/static/vendor/jquery/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="/static/vendor/bootstrap/js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>

    <!-- Google Maps API Key - Use your own API key to enable the map feature. More information on the Google Maps API can be found at https://developers.google.com/maps/ -->
    <script type="text/javascript" src="https://maps.googleapis.com/maps/api/js?key=AIzaSyCRngKslUGJTlibkQ3FkfTxj3Xss1UlZDA&sensor=false"></script>

    <!-- Theme JavaScript -->
    <script src="/static/js/grayscale.min.js"></script>

</body>

</html>
