{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cPickle as pickle\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import src.data_pipeline as dpl\n",
    "import src.fsm2 as fsm\n",
    "import src.predict_one as p_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_SVC():\n",
    "#     svm = LinearSVC(C=1.0, loss='squared_hinge', penalty='l2',multi_class='ovr')\n",
    "    svm = SVC(C=1.0, kernel='linear', degree=3, gamma='auto', coef0=0.0, shrinking=True,\n",
    "              probability=True, tol=0.001, cache_size=200, class_weight=None,\n",
    "              verbose=False, max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
    "\n",
    "    return svm\n",
    "\n",
    "# Create Model\n",
    "def create_RF():\n",
    "\n",
    "    rf = RF(n_estimators=60, criterion='gini', max_depth=200, \n",
    "          min_samples_split=2, min_samples_leaf=1, \n",
    "          min_weight_fraction_leaf=0.0, max_features=\"auto\", \n",
    "          max_leaf_nodes=None, min_impurity_split=1e-07, \n",
    "          bootstrap=True, oob_score=False, n_jobs=2, \n",
    "          random_state=None, verbose=0, warm_start=False, \n",
    "          class_weight=None)\n",
    "    \n",
    "    return rf\n",
    "\n",
    "def run_fit(model, X, y):\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(F,L, test_size=0.2, random_state=42)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)\n",
    "    return model, X_test, y_test, y_pred, y_prob\n",
    "\n",
    "def save_model(model, path_name):\n",
    "    with open(path_name, 'wb') as handle:\n",
    "        pickle.dump(model, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model(model, X_test, y_test):\n",
    "    # Modify for web app (or create new function)\n",
    "    # to predict one photo\n",
    "    def crossval(score_type):\n",
    "        try: score = cross_val_score(model, X_test, y_test,\n",
    "                            cv = 5, scoring= score_type)\n",
    "        except: score = 'invalid metric'\n",
    "\n",
    "        return score\n",
    "    \n",
    "    print \"accuracy : \", crossval('accuracy')\n",
    "    print \"precision: \", crossval('precision')\n",
    "    print \"recall   : \", crossval('recall')\n",
    "    print \"- logloss: \", crossval('neg_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping \"hare\" for balance\n"
     ]
    }
   ],
   "source": [
    "F,L,paths = fsm.prep_data('second_sample_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total value counts: \n",
      "ungulate    193\n",
      "small       104\n",
      "other       101\n",
      "canine       95\n",
      "feline       43\n",
      "Name: labels, dtype: int64\n",
      "\n",
      "Test set value counts:\n",
      "ungulate    37\n",
      "canine      20\n",
      "small       20\n",
      "other       19\n",
      "feline      12\n",
      "Name: labels, dtype: int64\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[20  0  0  0  0]\n",
      " [ 0 11  0  1  0]\n",
      " [ 0  0 18  0  1]\n",
      " [ 1  0  0 19  0]\n",
      " [ 0  0  0  0 37]]\n",
      "\n",
      "Percentage (sort of)\n",
      "[[ 100.            0.            0.            0.            0.        ]\n",
      " [   0.           91.66666667    0.            8.33333333    0.        ]\n",
      " [   0.            0.           94.73684211    0.            5.26315789]\n",
      " [   5.            0.            0.           95.            0.        ]\n",
      " [   0.            0.            0.            0.          100.        ]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = create_SVC()\n",
    "model, X_test, y_test, y_pred, y_prob = run_fit(svm,F,L)\n",
    "\n",
    "# Manually put labels in order\n",
    "alph_val_count = np.array([[20, 12, 19, 20, 37]])\n",
    "percent_matrix = confusion_matrix(y_test,y_pred)*100/alph_val_count.T\n",
    "\n",
    "print \"Total value counts: \\n\",L.value_counts()\n",
    "print \"\\nTest set value counts:\\n\",y_test.value_counts()\n",
    "print '\\nTest Confusion Matrix:\\n',confusion_matrix(y_test,y_pred)\n",
    "print '\\nPercentage (sort of)\\n', percent_matrix\n",
    "print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model(svm, 'data/svm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  [ 0.91304348  0.91304348  0.95238095  0.95238095  0.9       ]\n",
      "precision:  invalid metric\n",
      "recall   :  invalid metric\n",
      "- logloss:  [-0.3787518  -0.41039874 -0.39754279 -0.35578358 -0.45175097]\n"
     ]
    }
   ],
   "source": [
    "eval_model(svm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total value counts: \n",
      "ungulate    193\n",
      "small       104\n",
      "other       101\n",
      "canine       95\n",
      "feline       43\n",
      "Name: labels, dtype: int64\n",
      "\n",
      "Test set value counts:\n",
      "ungulate    37\n",
      "canine      20\n",
      "small       20\n",
      "other       19\n",
      "feline      12\n",
      "Name: labels, dtype: int64\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[19  0  0  0  1]\n",
      " [ 1 11  0  0  0]\n",
      " [ 0  0 13  0  6]\n",
      " [ 5  0  1 13  1]\n",
      " [ 0  0  0  0 37]]\n",
      "\n",
      "Percentage (sort of)\n",
      "[[  95.            0.            0.            0.            5.        ]\n",
      " [   8.33333333   91.66666667    0.            0.            0.        ]\n",
      " [   0.            0.           68.42105263    0.           31.57894737]\n",
      " [  25.            0.            5.           65.            5.        ]\n",
      " [   0.            0.            0.            0.          100.        ]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = create_RF()\n",
    "rf, X_test, y_test, y_pred, y_prob = run_fit(rf,F,L)\n",
    "\n",
    "# Manually put labels in order\n",
    "alph_val_count = np.array([[20, 12, 19, 20, 37]])\n",
    "percent_matrix = confusion_matrix(y_test,y_pred)*100/alph_val_count.T\n",
    "\n",
    "print \"Total value counts: \\n\",L.value_counts()\n",
    "print \"\\nTest set value counts:\\n\",y_test.value_counts()\n",
    "print '\\nTest Confusion Matrix:\\n',confusion_matrix(y_test,y_pred)\n",
    "print '\\nPercentage (sort of)\\n', percent_matrix\n",
    "print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  [ 0.82608696  0.7826087   0.9047619   0.85714286  0.85      ]\n",
      "precision:  invalid metric\n",
      "recall   :  invalid metric\n",
      "- logloss:  [-0.72018617 -0.80430246 -0.74306494 -0.66075032 -0.75257739]\n"
     ]
    }
   ],
   "source": [
    "eval_model(rf, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
