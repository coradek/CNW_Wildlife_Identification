{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from __future__ import division\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openCV basics\n",
    "### viewing and playing with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    # img = cv2.cvtColor(img, cv2.cv.CV_BGR2RGB)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "def show_img(img, title = None):\n",
    "    plt.subplot(111)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "    \n",
    "def sidebyside(im1,im2):\n",
    "    '''plot 2 (or more - if I feel dedicated) images side by side'''\n",
    "    \n",
    "    plt.subplot(1, 2, 1)         # #rows, #cols, plotnumber\n",
    "    plt.imshow(im1, cmap='gray') # First plot\n",
    "    plt.title('plot 1')\n",
    "\n",
    "    plt.subplot(1, 2, 2)         # #rows, #cols, plotnumber\n",
    "    plt.imshow(im2, cmap='gray') # plot in a separate subplot\n",
    "    plt.title('plot 2')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def gray_blur(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img = cv2.GaussianBlur(img, (21, 21), 0)\n",
    "    return img\n",
    "\n",
    "def img_diff(img1, img2, threshold = 60):\n",
    "    gray1 = gray_blur(img1)\n",
    "    gray2 = gray_blur(img2)\n",
    "    \n",
    "    dif = cv2.absdiff(gray1, gray2)\n",
    "    dif = cv2.threshold(dif, threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    show_img(dif)\n",
    "\n",
    "def event_diff(color_list, thresh=15):\n",
    "    img_list = color_list[:]          #  Copy list of color images ()\n",
    "    \n",
    "    for i, im in enumerate(img_list):\n",
    "        img_list[i] = gray_blur(im)\n",
    "    \n",
    "    def getdif(im1,im2):\n",
    "        dif = cv2.absdiff(im1, im2)\n",
    "        dif = cv2.threshold(dif, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "        return dif\n",
    "    \n",
    "    for i, im in enumerate(img_list[1:-1]):\n",
    "        \n",
    "        prev = getdif(im, img_list[i])\n",
    "        post = getdif(im, img_list[i+2])\n",
    "        both = cv2.bitwise_and(prev,post)\n",
    "        \n",
    "#         show_img(prev, title= 'prev')\n",
    "#         show_img(post, title= 'post')\n",
    "\n",
    "#         show_img(both, title='image at index '+str(i+1))\n",
    "        sidebyside(both, color_list[i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mossy the dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mossy = get_image('../images/mossydeer.jpg')\n",
    "nomossy = get_image('../images/nomossy.jpg')\n",
    "bgr_mossy = cv2.cvtColor(mossy, cv2.COLOR_RGB2BGR)\n",
    "gray_mossy = cv2.cvtColor(mossy, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show_img(mossy,)\n",
    "# show_img(nomossy)\n",
    "\n",
    "# img_diff(mossy, nomossy)\n",
    "\n",
    "sidebyside(mossy, nomossy)\n",
    "\n",
    "# # show_img(bgr_mossy)\n",
    "# # show_img(gray_mossy, title = 'gray mossy?', cmap='gray')\n",
    "\n",
    "# # show_img(mossy - nomossy)\n",
    "# # show_img((mossy + nomossy)/2)\n",
    "# # show_img(mossy-((mossy + nomossy)/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Playing with deer images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deer1 = get_image('../data/motion_test/EK000025-2.JPG')\n",
    "deer2 = get_image('../data/motion_test/EK000026-2.JPG')\n",
    "deer3 = get_image('../data/motion_test/EK000027-2.JPG')\n",
    "\n",
    "gray1 = cv2.cvtColor(deer1, cv2.COLOR_RGB2GRAY)\n",
    "gray2 = cv2.cvtColor(deer2, cv2.COLOR_RGB2GRAY)\n",
    "gray3 = cv2.cvtColor(deer3, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "blur1 = cv2.GaussianBlur(gray1, (21, 21), 0)\n",
    "blur2 = cv2.GaussianBlur(gray2, (21, 21), 0)\n",
    "blur3 = cv2.GaussianBlur(gray3, (21, 21), 0)\n",
    "\n",
    "# floor_avg= (deer1+deer2+deer3)//3\n",
    "# avg_deer = (deer1+deer2+deer3)/3.0\n",
    "# geomean = geo_mean([gray1, gray2, gray3])\n",
    "\n",
    "# roundeer1 = np.around(deer1, -2)\n",
    "# rd2 = np.around(deer2, -2)\n",
    "# rd3 = np.around(deer3, -2)\n",
    "# ravg = (roundeer1 + rd2 + rd3)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show_img(deer1)\n",
    "show_img(deer2)\n",
    "# show_img(deer3)\n",
    "\n",
    "# img_diff(deer2, deer1, threshold = 20)\n",
    "# img_diff(deer2, deer3, threshold = 20)\n",
    "\n",
    "################\n",
    "event = [deer1, deer2, deer3]\n",
    "event_diff(event, thresh = 5)\n",
    "\n",
    "# event_diff(event, thresh = 3)\n",
    "# event_diff(event, thresh = 15)\n",
    "\n",
    "\n",
    "################\n",
    "# event = [deer2, deer1, deer3]\n",
    "# event_diff(event, thresh = 10)\n",
    "\n",
    "\n",
    "################\n",
    "# event = [deer2, deer3, deer1]\n",
    "# event_diff(event, thresh = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Larger image groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = \"../data/second_sample/BC Kettles/Site 1/\"\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "#     for name in files:\n",
    "#         print(os.path.join(root, name))\n",
    "    for name in dirs:\n",
    "        print(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "event_bunch = []\n",
    "for dr in os.listdir(data_dir)[1:]:\n",
    "    ev = [get_image(os.path.join(data_dir, dr, im)) for im in os.listdir(os.path.join(data_dir, dr))]\n",
    "    event_bunch.append(ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(event_bunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ev = event_bunch[3]\n",
    "event_diff(ev, thresh=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i, im in enumerate(event_bunch[0]):\n",
    "#     show_img(im, title='image at index '+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Background Subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Borrowed from:\n",
    "#### http://www.pyimagesearch.com/2015/05/25/basic-motion-detection-and-tracking-with-python-and-opencv/#\n",
    "\n",
    "```python\n",
    "\n",
    "# loop over the frames of the video\n",
    "while True:\n",
    "\t# grab the current frame and initialize the occupied/unoccupied\n",
    "\t# text\n",
    "\t(grabbed, frame) = camera.read()\n",
    "\ttext = \"Unoccupied\"\n",
    " \n",
    "\t# if the frame could not be grabbed, then we have reached the end\n",
    "\t# of the video\n",
    "\tif not grabbed:\n",
    "\t\tbreak\n",
    " \n",
    "\t# resize the frame, convert it to grayscale, and blur it\n",
    "\tframe = imutils.resize(frame, width=500)\n",
    "\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\tgray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    " \n",
    "\t# if the first frame is None, initialize it\n",
    "\tif firstFrame is None:\n",
    "\t\tfirstFrame = gray\n",
    "\t\tcontinue\n",
    "\n",
    "\t# compute the absolute difference between the current frame and\n",
    "\t# first frame\n",
    "\tframeDelta = cv2.absdiff(firstFrame, gray)\n",
    "\tthresh = cv2.threshold(frameDelta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    " \n",
    "\t# dilate the thresholded image to fill in holes, then find contours\n",
    "\t# on thresholded image\n",
    "\tthresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\t(cnts, _) = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
    " \n",
    "\t# loop over the contours\n",
    "\tfor c in cnts:\n",
    "\t\t# if the contour is too small, ignore it\n",
    "\t\tif cv2.contourArea(c) < args[\"min_area\"]:\n",
    "\t\t\tcontinue\n",
    " \n",
    "\t\t# compute the bounding box for the contour, draw it on the frame,\n",
    "\t\t# and update the text\n",
    "\t\t(x, y, w, h) = cv2.boundingRect(c)\n",
    "\t\tcv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\t\ttext = \"Occupied\"\n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subtracting weighted average\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "c = cv2.VideoCapture(0)\n",
    "_,f = c.read()\n",
    " \n",
    "avg1 = np.float32(f)\n",
    "avg2 = np.float32(f)\n",
    " \n",
    "while(1):\n",
    "    _,f = c.read()\n",
    "     \n",
    "    cv2.accumulateWeighted(f,avg1,0.1)\n",
    "    cv2.accumulateWeighted(f,avg2,0.01)\n",
    "     \n",
    "    res1 = cv2.convertScaleAbs(avg1)\n",
    "    res2 = cv2.convertScaleAbs(avg2)\n",
    " \n",
    "    cv2.imshow('img',f)\n",
    "    cv2.imshow('avg1',res1)\n",
    "    cv2.imshow('avg2',res2)\n",
    "    k = cv2.waitKey(20)\n",
    " \n",
    "    if k == 27:\n",
    "        break\n",
    " \n",
    "cv2.destroyAllWindows()\n",
    "c.release()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def geo_mean(im_list):\n",
    "#     geo = reduce(lambda x, y: x*y, im_list)**(1.0/len(im_list))\n",
    "#     return geo\n",
    "\n",
    "\n",
    "# three_dif([deer1, deer2, deer3])\n",
    "\n",
    "# show_img(avg_deer, title = '3 Image Average')\n",
    "# show_img(floor_avg, title = '3 Image floor division')\n",
    "\n",
    "# show_img(256-3*avg_deer)\n",
    "# show_img(deer3-(256-3*avg_deer))\n",
    "# show_img(deer3)\n",
    "\n",
    "# show_img(geomean, title = 'geometric mean')\n",
    "\n",
    "\n",
    "# show_img(deer1-floor_avg, title = 'deer1')\n",
    "\n",
    "# show_img(ravg)\n",
    "# show_img(deer1-ravg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
